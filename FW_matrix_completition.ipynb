{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Imports\n",
    "from scipy import sparse\n",
    "import scipy\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from numpy import linalg as LA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Frank-Wolfe - standard algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kobsOmgimqL_",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# FW objective function\n",
    "def FW_objective_function(diff_vec):\n",
    "    return 0.5*(np.power(diff_vec,2).sum())\n",
    "\n",
    "# Regular FW algorithm\n",
    "def FrankWolfe(X, objective_function, delta, empties = 0, printing_res = True, Z_init = None, max_iter = 150, patience = 1e-3):\n",
    "    '''\n",
    "    :param X: sparse matrix with ratings and 'empty values', rows - users, columns - books.\n",
    "    :param objective_function: objective function that we would like to minimize with FW\n",
    "    :param delta: Radius of the feasible's set ball\n",
    "    :param empties (optional): Empty values of X are zeros (0) or NaN ('nan'). Default = 0\n",
    "    :param Z_init (optional): In case we want to initialize Z with a known matrix, if not given Z_init will be a zeros matrix. Default = None.\n",
    "    :param max_iter (optional): max number of iterations for the method. Default = 150.\n",
    "    :param patience (optional): once reached this tolerance provide the result. Default = 1e-3.\n",
    "    :return: Z: matrix of predicted ratings - it should be like X but with no 'empty values'\n",
    "    :return: accuracy: difference between original values (X) and predicted ones (Z)\n",
    "    '''\n",
    "\n",
    "    # Get X indexes for not empty values\n",
    "    if empties == 0:\n",
    "        idx_ratings = np.argwhere(X != 0)\n",
    "    elif empties == 'nan':\n",
    "        idx_ratings = np.argwhere(~np.isnan(X))\n",
    "    else:\n",
    "        return print('Error: Empties argument', empties, 'not valid.')\n",
    "\n",
    "    idx_rows = idx_ratings[:,0]\n",
    "    idx_cols = idx_ratings[:,1]\n",
    "\n",
    "    # Initialize Z\n",
    "    if Z_init == 'random uniform':\n",
    "        Z = np.random.uniform(low = 0.01, high = 1, size = X.shape)\n",
    "    elif Z_init is not None:\n",
    "        Z = Z_init\n",
    "    else:\n",
    "        Z = np.zeros(X.shape)\n",
    "\n",
    "    # Create vectors with the not empty features of the sparse matrix\n",
    "    X_rated = X[idx_rows, idx_cols]\n",
    "    Z_rated = Z[idx_rows, idx_cols]\n",
    "    diff_vec = np.array(Z_rated - X_rated)[0]\n",
    "\n",
    "    # Create needed variables\n",
    "    res_list = []\n",
    "    diff_loss = patience + 1\n",
    "    loss = objective_function(diff_vec)\n",
    "    it = 0\n",
    "    while (diff_loss > patience) and (it < max_iter):\n",
    "\n",
    "        # Gradient\n",
    "        grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "\n",
    "        # SVD - Compute k = 1 singular values and its vectors, starting from the largest (which = 'LM')\n",
    "        u_max, s_max, v_max = sparse.linalg.svds(grad, k = 1, which='LM')   #\n",
    "\n",
    "        # Update\n",
    "        Zk_tilde = -delta*np.outer(u_max,v_max)\n",
    "\n",
    "        alpha_k = 2/(it+2) #alpha - as studied in class\n",
    "        Z = (1-alpha_k)*Z + alpha_k*Zk_tilde\n",
    "\n",
    "        # Loss\n",
    "        diff_vec = np.array(Z[idx_rows, idx_cols] - X_rated)[0]\n",
    "        new_loss = objective_function(diff_vec)\n",
    "\n",
    "        # Improvement at this iteration\n",
    "        diff_loss = np.abs(loss - new_loss)\n",
    "        loss = new_loss\n",
    "\n",
    "        if printing_res == True:\n",
    "            if it == 1 or it % 10 == 0:\n",
    "                print('Iteration:', it, 'Loss:', loss, 'Loss diff:', diff_loss, 'Rank(Z): ', np.linalg.matrix_rank(Z))\n",
    "\n",
    "        # Count iteration\n",
    "        it += 1\n",
    "\n",
    "        res_list.append(loss)\n",
    "        \n",
    "    return Z, loss, res_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y-VOlLMvfq8"
   },
   "source": [
    "# Frank-Wolfe In-face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "time_out = time.process_time() + 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Binary search for alpha stop\n",
    "def alpha_binary_search(Zk, Dk, delta, max_value = 1, min_value = 0, tol = 0.3):\n",
    "\n",
    "    #Inizialization\n",
    "\n",
    "    best_alpha = (max_value - min_value) / 2\n",
    "\n",
    "    testing_matrix = Zk + best_alpha * Dk\n",
    "\n",
    "    sentinel = False\n",
    "\n",
    "    while time.process_time() <= time_out:\n",
    "\n",
    "      testing_mat_nuclear_norm = LA.norm(testing_matrix, ord = 'nuc')\n",
    "\n",
    "      sentinel = True\n",
    "\n",
    "    #Binary Search\n",
    "\n",
    "    if sentinel == True:\n",
    "\n",
    "      while testing_mat_nuclear_norm <= delta and (max_value - min_value) >= tol and time.process_time() <= time_out:\n",
    "\n",
    "          min_value = best_alpha\n",
    "\n",
    "          best_alpha = (max_value - min_value) / 2\n",
    "\n",
    "          testing_matrix = Zk + best_alpha * Dk\n",
    "\n",
    "          testing_mat_nuclear_norm = LA.norm(testing_matrix, ord = 'nuc')\n",
    "\n",
    "    return best_alpha"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def FW_inface(X, objective_function, delta, L = 1, D = None, gamma1 = 0, gamma2 = 1, THRES = 0.001, empties = 0, max_iter=150, patience=1e-3, printing = True):\n",
    "    '''\n",
    "    :param X: sparse matrix with ratings and 'empty values', rows - users, columns - books.\n",
    "    :param objective_function: objective function that we would like to minimize with FW.\n",
    "    :param delta: Radius of the feasible's set ball\n",
    "    :param L: must be greater than 1\n",
    "    :param D: if not inputed = 2*delta\n",
    "    :param gamma1:\n",
    "    :param gamma2:\n",
    "    :param THRES:\n",
    "    :param empties (optional): Empty values of X are zeros (0) or NaN ('nan'). Default = 0\n",
    "    :param max_iter: max number of iterations for the method.\n",
    "    :param patience: once reached this tolerance provide the result.\n",
    "    :return: Z: matrix of predicted ratings - it should be like X but with no 'empty values'\n",
    "            loss: difference between original values (X) and predicted ones (Z).\n",
    "    '''\n",
    "\n",
    "    # Get X indexes for not empty values\n",
    "    if empties == 0:\n",
    "        idx_ratings = np.argwhere(X != 0)\n",
    "    elif empties == 'nan':\n",
    "        idx_ratings = np.argwhere(~np.isnan(X))\n",
    "    else:\n",
    "        return print('Empties argument', empties, 'not valid.')\n",
    "\n",
    "    idx_rows = idx_ratings[:,0]\n",
    "    idx_cols = idx_ratings[:,1]\n",
    "\n",
    "    # Initialize Z_{-1}\n",
    "    Z_1 = np.zeros(X.shape)\n",
    "\n",
    "    # Create vectors with the not empty features of the sparse matrix\n",
    "    X_rated = X[idx_rows, idx_cols]\n",
    "    Z_rated = Z_1[idx_rows, idx_cols]\n",
    "    diff_vec_1 = np.array(Z_rated - X_rated)[0]\n",
    "\n",
    "    # Initial gradient and Z0\n",
    "    grad_1 = sparse.csr_matrix((diff_vec_1, (idx_rows, idx_cols)))\n",
    "    u_max, s_max, v_max = sparse.linalg.svds(grad_1, k = 1, which='LM')\n",
    "    Zk = -delta*np.outer(u_max,v_max)\n",
    "    Z_rated = Zk[idx_rows, idx_cols]\n",
    "\n",
    "    print('Initial Zk Rank: ', LA.matrix_rank(Zk))\n",
    "\n",
    "    # Initialize lower bound on the optimal objective function (f*)\n",
    "    diff_vec = np.array(Z_rated - X_rated)[0]\n",
    "    print(np.multiply(grad_1,Zk).sum())\n",
    "    new_low_bound = np.max((objective_function(diff_vec_1) + np.multiply(grad_1,Zk).sum()), 0)\n",
    "    #new_low_bound = 0 #used 0 otherwise the other new_low_bound was too high!\n",
    "    print(new_low_bound)\n",
    "    # Set D\n",
    "    if D is not None:\n",
    "        D = D\n",
    "    else:\n",
    "        D = 2*delta\n",
    "    print('After D')\n",
    "    rank_Z = LA.matrix_rank(Zk)   # rank of Zk to find thin SVD size\n",
    "\n",
    "    # Additional needed parameters\n",
    "    diff_loss = patience + 1\n",
    "    loss = objective_function(diff_vec)\n",
    "    it = 0\n",
    "    res_list = [loss]\n",
    "    not_in_ball=False\n",
    "\n",
    "    B_used = 0\n",
    "    A_used = 0\n",
    "    not_entered = 0\n",
    "    regularFW = 0\n",
    "\n",
    "    while (diff_loss > patience) and (it < max_iter):\n",
    "        print('entered while')\n",
    "\n",
    "        # Thin SVD\n",
    "        U_thin, s_thin, Vh_thin = sparse.linalg.svds(Zk, k = rank_Z, which='LM')   # Compute k = rank singular values\n",
    "\n",
    "        # Lower bound update\n",
    "        low_bound = new_low_bound\n",
    "\n",
    "        # Gradient\n",
    "        grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "\n",
    "        # In-face direction with the away step strategy: two calculations depending of where Z lies within the feasible set\n",
    "        if s_thin.sum() == delta: # Z in border (sum of singular values == radius of feasible set)\n",
    "            print('Zk in border!')\n",
    "            G = 0.5 * (Vh_thin.dot(grad.T.dot(U_thin)) + U_thin.T.dot(grad.dot(Vh_thin.T)))\n",
    "            # Obtain unitary eigenvector corresponding to smallest eigenvalue of G\n",
    "            eigvalues, eigvectors = LA.eig(G)  #find the eigenvalues\n",
    "            min_eig = np.argmin(eigvalues)  #find the index of the smallest eigenvalue\n",
    "            u = eigvectors[:, min_eig]  #take the eigenvector corresponding to the smallest eigenvalue\n",
    "            print(np.shape(u), u)\n",
    "\n",
    "            # Update value\n",
    "            M = np.outer(u,u.T)\n",
    "            print(M)\n",
    "            Zk_tilde = delta*U_thin.dot(M.dot(Vh_thin))\n",
    "            Dk = Zk - Zk_tilde\n",
    "\n",
    "            inv_s_thin = np.diag(1/s_thin)\n",
    "            alpha_stop = 1/(delta*u.T.dot(inv_s_thin.dot(u))-1)\n",
    "\n",
    "        elif s_thin.sum() < delta: #inside\n",
    "\n",
    "            u_max, s_max, v_max = sparse.linalg.svds(grad, k = 1, which='LM')\n",
    "            Zk_tilde = delta*np.outer(u_max,v_max)\n",
    "            Dk = Zk - Zk_tilde\n",
    "            #BINARY SEARCH\n",
    "            '''\n",
    "            alpha_stop = alpha_binary_search(Zk,\n",
    "                                          Dk,\n",
    "                                          delta)\n",
    "            '''\n",
    "            alpha_stop = 0.5\n",
    "        else:\n",
    "            not_in_ball = True\n",
    "\n",
    "\n",
    "\n",
    "        nuclear_norm = s_thin.sum()\n",
    "        print('thres:', abs(delta - nuclear_norm))\n",
    "        print('rank', rank_Z)\n",
    "        # We check if Zk is inside the feasible set and the rank in order to decide which type steps to do\n",
    "        if rank_Z > 1 and not_in_ball==False:\n",
    "            Z_B = Zk + alpha_stop*Dk\n",
    "            diff_vec_B = np.array(Z_B[idx_rows, idx_cols] - X_rated)[0]\n",
    "            #print('obj_B', objective_function(diff_vec_B),', obj:', loss, ',low bound:', low_bound)\n",
    "            if 1/(objective_function(diff_vec_B)-low_bound) >= (1/(loss-low_bound)+gamma1/(2*L*D**2)):\n",
    "              # 1. Move to a lower dimensional face\n",
    "              print('Went to a lower-dimensional face')\n",
    "              B_used += 1\n",
    "              Zk = Z_B\n",
    "\n",
    "            else:\n",
    "                beta = alpha_stop/5 # FIND A GOOD VALUE -- a binary search is also suggested by the paper\n",
    "                Z_A = Zk + beta*Dk\n",
    "                diff_vec_A = np.array(Z_A[idx_rows, idx_cols] - X_rated)[0]\n",
    "                if 1/(objective_function(diff_vec_A)-low_bound) >= (1/(loss-low_bound)+gamma2/(2*L*D**2)):\n",
    "                    # 2. Stay in the current face\n",
    "                    print('Stayed in the current face')\n",
    "                    A_used += 1\n",
    "                    Zk = Z_A\n",
    "                else:\n",
    "                    # 3. Do a regular FW step and update the lower bound\n",
    "                    print('Do a regular FW step')\n",
    "                    regularFW += 1\n",
    "                    #Zk update\n",
    "                    u_max, s_max, v_max = sparse.linalg.svds(grad, k = 1, which='LM')\n",
    "                    Zk_tilde = -delta*np.outer(u_max,v_max)\n",
    "\n",
    "                    '''# Lower bound update\n",
    "                    B_w = loss + grad.T.dot(Zk_tilde - Zk)\n",
    "                    print(B_w, low_bound)\n",
    "                    new_low_bound = np.max(low_bound, B_w)'''\n",
    "\n",
    "                    direction_vec = Zk_tilde.flatten() - Zk.flatten()\n",
    "                    grad = grad.toarray()\n",
    "                    wolfe_gap = grad.T.flatten() * direction_vec\n",
    "                    B_w = loss + wolfe_gap.sum()\n",
    "\n",
    "                    #TRIED THIS INSTEAD\n",
    "                    if low_bound >= B_w:\n",
    "                        new_low_bound = low_bound\n",
    "                    else:\n",
    "                        new_low_bound = B_w\n",
    "\n",
    "                    # Z_(k+1)\n",
    "                    alpha_k = 2/(it+2)\n",
    "                    Zk = (1-alpha_k)*Zk + alpha_k*Zk_tilde\n",
    "\n",
    "        else:\n",
    "\n",
    "            # 3. Do a regular FW step and update the lower bound\n",
    "            print('Do a regular FW step - not entered initial if')\n",
    "            not_entered += 1\n",
    "            #Zk update\n",
    "            grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "            u_max, s_max, v_max = sparse.linalg.svds(grad, k = 1, which='LM')\n",
    "            Zk_tilde = -delta*np.outer(u_max,v_max)\n",
    "\n",
    "            '''# Lower bound update\n",
    "            B_w = loss + grad.T.dot(Zk_tilde - Zk)\n",
    "            print(B_w, low_bound)\n",
    "            new_low_bound = np.max(low_bound, B_w)'''\n",
    "\n",
    "            direction_vec = Zk_tilde.flatten() - Zk.flatten()\n",
    "            grad = grad.toarray()\n",
    "            wolfe_gap = grad.T.flatten() * direction_vec\n",
    "            B_w = loss + wolfe_gap.sum()\n",
    "\n",
    "            #TRIED THIS INSTEAD\n",
    "            if low_bound >= B_w:\n",
    "                new_low_bound = low_bound\n",
    "            else:\n",
    "                new_low_bound = B_w\n",
    "\n",
    "            # Z_(k+1)\n",
    "            alpha_k = 2/(it+2)\n",
    "            Zk = (1-alpha_k)*Zk + alpha_k*Zk_tilde\n",
    "\n",
    "            not_in_ball=False\n",
    "\n",
    "        # Loss\n",
    "        diff_vec = np.array(Zk[idx_rows, idx_cols] - X_rated)[0]\n",
    "        new_loss = objective_function(diff_vec)\n",
    "\n",
    "        # Improvement at this iteration\n",
    "        diff_loss = np.abs(loss - new_loss)\n",
    "        loss = new_loss\n",
    "\n",
    "        rank_Z = LA.matrix_rank(Zk)   # rank of Zk to find thin SVD size\n",
    "\n",
    "        # Gradient\n",
    "        #grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "\n",
    "        # Count iteration\n",
    "        it += 1\n",
    "\n",
    "        res_list.append(loss)\n",
    "\n",
    "        if printing == True:\n",
    "          if it % 10 == 0 or it == 1:\n",
    "            print('Iteration:', it, 'Loss:', loss, 'Loss diff:', diff_loss, 'Rank(Z): ', rank_Z)\n",
    "\n",
    "    print('Went to lower dim face:', B_used)\n",
    "    print('Stayed:', A_used)\n",
    "    print('Regular:', regularFW)\n",
    "    print('Not entered if:', not_entered)\n",
    "    return Zk, loss, res_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Zk Rank:  1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [28]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pred_ratings, loss, res_listInFW \u001B[38;5;241m=\u001B[39m \u001B[43mFW_inface\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mFW_objective_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgamma1\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.05\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgamma2\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.15\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelta\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mTHRES\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1e-7\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36mFW_inface\u001B[1;34m(X, objective_function, delta, L, D, gamma1, gamma2, THRES, empties, max_iter, patience, printing)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# Initialize lower bound on the optimal objective function (f*)\u001B[39;00m\n\u001B[0;32m     46\u001B[0m diff_vec \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(Z_rated \u001B[38;5;241m-\u001B[39m X_rated)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m---> 47\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultiply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad_1\u001B[49m\u001B[43m,\u001B[49m\u001B[43mZk\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msum())\n\u001B[0;32m     48\u001B[0m new_low_bound \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmax((objective_function(diff_vec_1) \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39mmultiply(grad_1,Zk)\u001B[38;5;241m.\u001B[39msum()), \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m#new_low_bound = 0 #used 0 otherwise the other new_low_bound was too high!\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\_base.py:583\u001B[0m, in \u001B[0;36mspmatrix.__mul__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m    582\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__mul__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[1;32m--> 583\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mul_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\_base.py:529\u001B[0m, in \u001B[0;36mspmatrix._mul_dispatch\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m    525\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mul_multivector(other)\n\u001B[0;32m    527\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m isscalarlike(other):\n\u001B[0;32m    528\u001B[0m     \u001B[38;5;66;03m# scalar value\u001B[39;00m\n\u001B[1;32m--> 529\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mul_scalar\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(other):\n\u001B[0;32m    532\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m other\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\sparse\\_data.py:124\u001B[0m, in \u001B[0;36m_data_matrix._mul_scalar\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_mul_scalar\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[1;32m--> 124\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_with_data(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "pred_ratings, loss, res_listInFW = FW_inface(X_test, FW_objective_function, gamma1 = 0.05, gamma2 = 0.15, delta = 4, THRES = 10, max_iter = 100, patience = 1e-7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(res_listInFW)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuclear norm: 0.5704929492231393\n",
      "Data shape: (200, 400)\n",
      "Number of observed values: 14826\n",
      "Rank of the matrix: 1\n",
      "Minimum and maximum values: 0.05657176231878037 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: SparseEfficiencyWarning: Comparing a sparse matrix with 0 using == is inefficient, try using != instead.\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n = 400\n",
    "m = 200\n",
    "r = 10\n",
    "rho = 0.10\n",
    "SNR = 5\n",
    "delta = 3.75\n",
    "\n",
    "\n",
    "\n",
    "# taking data\n",
    "U = sparse.random(m, r, density=0.1, format='csr', data_rvs=None)\n",
    "V = sparse.random(r, n, density=0.1, format='csr', data_rvs=None)\n",
    "E = sparse.random(m, n, density=0.1, format='csr', data_rvs=None)\n",
    "\n",
    "\n",
    "\n",
    "VT = V.transpose(copy=True)\n",
    "\n",
    "UVT = U*V\n",
    "#print(UVT. shape)\n",
    "\n",
    "w1 = 1/(sparse.linalg.norm(UVT, ord='fro'))\n",
    "\n",
    "w2 = 1/(SNR*sparse.linalg.norm(E, ord='fro'))\n",
    "\n",
    "#Finally observed data matrix is:\n",
    "X_test = w1*UVT + w2*E\n",
    "\n",
    "# Non zero values\n",
    "idx_ratings = np.argwhere(X_test != 0.)\n",
    "idx_rows = idx_ratings[:,0]\n",
    "idx_cols = idx_ratings[:,1]\n",
    "\n",
    "# Nuclear norm of the test set\n",
    "rank = np.linalg.matrix_rank(X_test)\n",
    "U_thin, s_thin, Vh_thin = sparse.linalg.svds(X_test, k = rank, which='LM')\n",
    "nuc_norm = s_thin.sum()\n",
    "\n",
    "# Print some info about the generated data\n",
    "print('Nuclear norm:', nuc_norm)\n",
    "print('Data shape:', np.shape(X_test))\n",
    "print('Number of observed values:', len(idx_rows))\n",
    "print('Rank of the matrix:', rank)\n",
    "print('Minimum and maximum values:', X_test.max(), X_test.min())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Loss: 2.66508691172435 Loss diff: 2.132320931010145 Rank(Z):  1\n",
      "Iteration: 1 Loss: 2.2149369654002298 Loss diff: 0.4501499463241201 Rank(Z):  2\n",
      "Iteration: 10 Loss: 0.24763703376072013 Loss diff: 0.03047711083699653 Rank(Z):  11\n",
      "Iteration: 20 Loss: 0.07361579406635789 Loss diff: 0.002078575501758176 Rank(Z):  21\n",
      "Iteration: 30 Loss: 0.03706836499981142 Loss diff: 0.0024735246718667683 Rank(Z):  31\n",
      "Iteration: 40 Loss: 0.029738788200615006 Loss diff: 0.0026758100085918016 Rank(Z):  41\n",
      "Iteration: 50 Loss: 0.020323323879564134 Loss diff: 0.003770218891604095 Rank(Z):  51\n",
      "Iteration: 60 Loss: 0.01650696136019946 Loss diff: 0.00026738186069183434 Rank(Z):  61\n",
      "Iteration: 70 Loss: 0.015063932569846141 Loss diff: 0.0006015638975318763 Rank(Z):  71\n",
      "Iteration: 80 Loss: 0.012608417441519137 Loss diff: 0.0005573396601608483 Rank(Z):  81\n",
      "Iteration: 90 Loss: 0.012853966186621013 Loss diff: 0.0008863597768841835 Rank(Z):  91\n",
      "CPU times: total: 734 ms\n",
      "Wall time: 741 ms\n"
     ]
    }
   ],
   "source": [
    "%time pred_ratings_reg, loss_reg, loss_track_reg = FrankWolfe(X_test, FW_objective_function, delta = 4, max_iter=100, patience=1e-7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log10(loss_track_reg))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Zk Rank:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time pred_ratings_inface, loss_inface, loss_track_inface = FW_inface(X_test, FW_objective_function, gamma1 = 0.05, gamma2 = 0.15, delta = 4, THRES = 10, max_iter = 100, patience = 1e-7, printing=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_track_inface)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwQyN3Cy_uF5"
   },
   "source": [
    "# Tuned Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_track_reg, label = 'Frank Wolfe')\n",
    "plt.plot(loss_track_inface, label = 'In-Face Frank Wolfe')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0manG1buepT"
   },
   "source": [
    "# Grid Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_MUb9nrwJyA"
   },
   "source": [
    "##Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUZGgSUsudah",
    "outputId": "bd7fb5f1-3a5b-4467-e5cc-23f3784569fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 0.001    ------     Final Loss: 1995299.6906607011   at iteration 2\n",
      "Delta: 0.01    ------     Final Loss: 1995296.9066038157   at iteration 2\n",
      "Delta: 0.1    ------     Final Loss: 1995269.065718345   at iteration 2\n",
      "Delta: 1    ------     Final Loss: 1994990.6592616318   at iteration 4\n",
      "Delta: 10    ------     Final Loss: 1992207.8429168023   at iteration 19\n",
      "Delta: 100    ------     Final Loss: 1964496.978598407   at iteration 84\n",
      "Delta: 1000    ------     Final Loss: 1699162.6623283497   at iteration 201\n",
      "Delta: 10000    ------     Final Loss: 302150.77467486466   at iteration 64\n",
      "Delta: 100000    ------     Final Loss: 175474.63085276185   at iteration 70\n",
      "Delta: 1000000    ------     Final Loss: 146671.28662048402   at iteration 201\n",
      "Delta: 10000000    ------     Final Loss: 672843.1813172555   at iteration 201\n",
      "Delta: 100000000    ------     Final Loss: 1757112480.4694064   at iteration 201\n"
     ]
    }
   ],
   "source": [
    "deltas = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000]\n",
    "\n",
    "for delta in deltas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, delta = delta, max_iter=201, patience = 0.01, printing = False)\n",
    "  print('Delta: ' + str(delta) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--BkRQqIxmSw",
    "outputId": "f9c17983-9fb7-40c8-dc83-c9d8c099cf3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 250000    ------     Final Loss: 184966.58801373874   at iteration 142\n",
      "Delta: 500000    ------     Final Loss: 169552.51866399613   at iteration 201\n",
      "Delta: 750000    ------     Final Loss: 420615.6132565984   at iteration 201\n",
      "Delta: 1250000    ------     Final Loss: 216412.31880627264   at iteration 201\n",
      "Delta: 1500000    ------     Final Loss: 273680.42343568715   at iteration 201\n",
      "Delta: 2500000    ------     Final Loss: 417712.4612960932   at iteration 201\n",
      "Delta: 5000000    ------     Final Loss: 571545.4612269908   at iteration 201\n",
      "Delta: 7500000    ------     Final Loss: 632556.1542439449   at iteration 201\n"
     ]
    }
   ],
   "source": [
    "deltas = [250000,\n",
    "          500000,\n",
    "          750000,\n",
    "          1250000,\n",
    "          1500000,\n",
    "          2500000,\n",
    "          5000000,\n",
    "          7500000]\n",
    "\n",
    "for delta in deltas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, delta = delta, max_iter=201, patience = 0.01, printing = False)\n",
    "  print('Delta: ' + str(delta) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5Xei-9Gy3hh",
    "outputId": "47a9fd59-b0a5-4bca-ab08-992677a90c73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 150000    ------     Final Loss: 180502.69121015765   at iteration 95\n",
      "Delta: 300000    ------     Final Loss: 186151.14181067253   at iteration 165\n",
      "Delta: 450000    ------     Final Loss: 188191.3045520871   at iteration 231\n",
      "Delta: 600000    ------     Final Loss: 189243.6150128576   at iteration 297\n",
      "Delta: 900000    ------     Final Loss: 190318.32554160611   at iteration 425\n",
      "Delta: 1200000    ------     Final Loss: 189679.94593613478   at iteration 501\n",
      "Delta: 1500000    ------     Final Loss: 149600.4326080835   at iteration 501\n"
     ]
    }
   ],
   "source": [
    "deltas = [150000,\n",
    "          300000,\n",
    "          450000,\n",
    "          600000,\n",
    "          900000,\n",
    "          1200000,\n",
    "          1500000]\n",
    "\n",
    "for delta in deltas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, delta = delta, max_iter=501, patience = 0.01, printing = False)\n",
    "  print('Delta: ' + str(delta) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2W5PqtaH0eZu",
    "outputId": "c519e67f-c98e-4186-a5a2-8d0d6a031872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 1750000    ------     Final Loss: 191384.43819455765   at iteration 786\n",
      "Delta: 2000000    ------     Final Loss: 191527.2106760225   at iteration 889\n",
      "Delta: 2250000    ------     Final Loss: 191638.53051798942   at iteration 991\n"
     ]
    }
   ],
   "source": [
    "deltas = [1750000,\n",
    "          2000000,\n",
    "          2250000]\n",
    "\n",
    "for delta in deltas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, delta = delta, max_iter = 1000, patience = 0.001, printing = False)\n",
    "  print('Delta: ' + str(delta) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkpvJqQi2YxJ",
    "outputId": "c4eeadcf-f4a5-4873-94aa-33a40b766bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 1375000    ------     Final Loss: 191074.29727334835   at iteration 630\n",
      "Delta: 1500000    ------     Final Loss: 191194.6863524153   at iteration 682\n",
      "Delta: 1625000    ------     Final Loss: 191296.77299220837   at iteration 734\n"
     ]
    }
   ],
   "source": [
    "deltas = [1375000,\n",
    "          1500000,\n",
    "          1625000]\n",
    "\n",
    "for delta in deltas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, delta = delta, max_iter = 1000, patience = 0.001, printing = False)\n",
    "  print('Delta: ' + str(delta) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PO5uv6UZ33wJ"
   },
   "source": [
    "## Gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45FR0xoX323p",
    "outputId": "51369768-d4dc-4455-f573-83822546ef54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma1: 0   Gamma2: 0.1    ------     Final Loss: 335449.4737096828   at iteration 500\n",
      "Gamma1: 0   Gamma2: 1    ------     Final Loss: 335449.4737096833   at iteration 500\n",
      "Gamma1: 0.1   Gamma2: 1    ------     Final Loss: 149460.45148459333   at iteration 500\n",
      "Gamma1: 1   Gamma2: 1    ------     Final Loss: 149460.451484515   at iteration 500\n",
      "Gamma1: 1   Gamma2: 10    ------     Final Loss: 335449.47370968235   at iteration 500\n",
      "Gamma1: 1   Gamma2: 100    ------     Final Loss: 149460.4514845148   at iteration 500\n",
      "Gamma1: 10   Gamma2: 100    ------     Final Loss: 149460.451484515   at iteration 500\n"
     ]
    }
   ],
   "source": [
    "gammas = [[0,    0.1],\n",
    "          [0,    1],\n",
    "          [0.1,  1],\n",
    "          [1,    1],\n",
    "          [1,   10],\n",
    "          [1,  100],\n",
    "          [10, 100]]\n",
    "\n",
    "for gamma1, gamma2 in gammas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, gamma1 = gamma1, gamma2 = gamma2, delta = 1500000, max_iter = 500, patience = 0.001, printing = False)\n",
    "  print('Gamma1: ' + str(gamma1) + '   Gamma2: ' + str(gamma2) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOD4CGHO884Z",
    "outputId": "f4ddeb2d-b605-4c9c-fab8-d096648bc3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma1: 1   Gamma2: 100    ------     Final Loss: 149460.45148459318   at iteration 500\n",
      "Gamma1: 100   Gamma2: 100    ------     Final Loss: 149460.45148451466   at iteration 500\n",
      "Gamma1: 0.1   Gamma2: 100    ------     Final Loss: 149460.4514845149   at iteration 500\n",
      "Gamma1: 1   Gamma2: 1000    ------     Final Loss: 335449.4737115356   at iteration 500\n"
     ]
    }
   ],
   "source": [
    "gammas = [[1,  100],\n",
    "          [100, 100],\n",
    "          [0.1,  100],\n",
    "          [1,    1000]]\n",
    "\n",
    "for gamma1, gamma2 in gammas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, gamma1 = gamma1, gamma2 = gamma2, delta = 1500000, max_iter = 500, patience = 0.001, printing = False)\n",
    "  print('Gamma1: ' + str(gamma1) + '   Gamma2: ' + str(gamma2) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMpXvq5S-ZvP",
    "outputId": "ac623233-b516-433e-a7f7-041981b1ed94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma1: 0   Gamma2: 100    ------     Final Loss: 335449.47371153446   at iteration 500\n",
      "Gamma1: 0   Gamma2: 1000    ------     Final Loss: 149460.4514845933   at iteration 500\n",
      "Gamma1: 0.1   Gamma2: 0.1    ------     Final Loss: 149460.45148451495   at iteration 500\n"
     ]
    }
   ],
   "source": [
    "gammas = [[0,  100],\n",
    "          [0, 1000],\n",
    "          [0.1,  0.1]]\n",
    "\n",
    "for gamma1, gamma2 in gammas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, gamma1 = gamma1, gamma2 = gamma2, delta = 1500000, max_iter = 500, patience = 0.001, printing = False)\n",
    "  print('Gamma1: ' + str(gamma1) + '   Gamma2: ' + str(gamma2) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpS5jRz4vpHa"
   },
   "source": [
    "## Sub-Chapter"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FW_GoodReads_recommender - Copia.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}