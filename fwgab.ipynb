{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M9fwkajk0JFu",
    "outputId": "666d2b91-87e1-47e4-d855-9361da170792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65ARbMD3vBTq"
   },
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Vm7PYy7xNGZ"
   },
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ECj6WKmZ0XzI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0Yt6f1OK0n0b"
   },
   "outputs": [],
   "source": [
    "path = 'goodreads_cleaned.csv'\n",
    "#path = 'DATA/goodreads_cleaned.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "XPZR6p810sja",
    "outputId": "a2f5b267-c72b-435c-8ceb-3decc16d90e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>18245960</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>16981</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>28684704</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>27161156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8842281e1d1347389f2ab93d60773d4d</td>\n",
       "      <td>25884323</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899995</th>\n",
       "      <td>b9450d1c1f97f891c392b1105959b56e</td>\n",
       "      <td>11832081</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899996</th>\n",
       "      <td>b9450d1c1f97f891c392b1105959b56e</td>\n",
       "      <td>16095092</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899997</th>\n",
       "      <td>b9450d1c1f97f891c392b1105959b56e</td>\n",
       "      <td>8430896</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899998</th>\n",
       "      <td>b9450d1c1f97f891c392b1105959b56e</td>\n",
       "      <td>12275680</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899999</th>\n",
       "      <td>b9450d1c1f97f891c392b1105959b56e</td>\n",
       "      <td>17005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_id   book_id  rating\n",
       "0       8842281e1d1347389f2ab93d60773d4d  18245960       5\n",
       "1       8842281e1d1347389f2ab93d60773d4d     16981       3\n",
       "2       8842281e1d1347389f2ab93d60773d4d  28684704       3\n",
       "3       8842281e1d1347389f2ab93d60773d4d  27161156       0\n",
       "4       8842281e1d1347389f2ab93d60773d4d  25884323       4\n",
       "...                                  ...       ...     ...\n",
       "899995  b9450d1c1f97f891c392b1105959b56e  11832081       3\n",
       "899996  b9450d1c1f97f891c392b1105959b56e  16095092       3\n",
       "899997  b9450d1c1f97f891c392b1105959b56e   8430896       4\n",
       "899998  b9450d1c1f97f891c392b1105959b56e  12275680       4\n",
       "899999  b9450d1c1f97f891c392b1105959b56e     17005       3\n",
       "\n",
       "[900000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path, sep = \";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPE9r1Q4xT1Z"
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xBrJsOa1nmZl",
    "outputId": "b9f755b6-5cb2-48b8-ed8b-57334dd14126"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12188.000000\n",
       "mean        73.843124\n",
       "std        103.860677\n",
       "min          1.000000\n",
       "25%         14.000000\n",
       "50%         37.000000\n",
       "75%         92.000000\n",
       "max       1815.000000\n",
       "Name: user_id, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.user_id.value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JH79waI4pO83",
    "outputId": "7816cc4f-5c08-4b20-dde8-36f3c9f130c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    25474.000000\n",
       "mean        35.330141\n",
       "std         67.222413\n",
       "min          1.000000\n",
       "25%         10.000000\n",
       "50%         17.000000\n",
       "75%         34.000000\n",
       "max       1734.000000\n",
       "Name: book_id, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.book_id.value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRNXYn4cxeG5"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Vbw2KbXRpvEK"
   },
   "outputs": [],
   "source": [
    "df['book_id_count'] = df.groupby('book_id')['book_id'].transform('count')\n",
    "df['user_id_count'] = df.groupby('user_id')['user_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NTP9FUQmsJeX"
   },
   "outputs": [],
   "source": [
    "book_quantile = 0.95\n",
    "user_quantile = 0.9\n",
    "\n",
    "df = df.loc[(df.book_id_count >= df.book_id.value_counts().quantile(book_quantile)) & (df.user_id_count >= df.user_id.value_counts().quantile(user_quantile)),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lwiSPjEwmqL7",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "50f4e346-9cec-4600-8931-0daaa08c04c8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114041, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMoKEdpWxnWc"
   },
   "source": [
    "## Data Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "p0BWaRDjApkr",
    "outputId": "ab3073df-b00f-4db4-b602-d686111123e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>book_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>11</th>\n",
       "      <th>34</th>\n",
       "      <th>830</th>\n",
       "      <th>865</th>\n",
       "      <th>890</th>\n",
       "      <th>902</th>\n",
       "      <th>930</th>\n",
       "      <th>960</th>\n",
       "      <th>968</th>\n",
       "      <th>1103</th>\n",
       "      <th>1232</th>\n",
       "      <th>1617</th>\n",
       "      <th>1618</th>\n",
       "      <th>1622</th>\n",
       "      <th>1845</th>\n",
       "      <th>1885</th>\n",
       "      <th>1934</th>\n",
       "      <th>1953</th>\n",
       "      <th>2156</th>\n",
       "      <th>2165</th>\n",
       "      <th>2187</th>\n",
       "      <th>2493</th>\n",
       "      <th>2526</th>\n",
       "      <th>2623</th>\n",
       "      <th>2657</th>\n",
       "      <th>2744</th>\n",
       "      <th>2839</th>\n",
       "      <th>2998</th>\n",
       "      <th>3431</th>\n",
       "      <th>3473</th>\n",
       "      <th>3636</th>\n",
       "      <th>3682</th>\n",
       "      <th>4214</th>\n",
       "      <th>4381</th>\n",
       "      <th>4407</th>\n",
       "      <th>4588</th>\n",
       "      <th>4671</th>\n",
       "      <th>4929</th>\n",
       "      <th>4981</th>\n",
       "      <th>5043</th>\n",
       "      <th>5107</th>\n",
       "      <th>5129</th>\n",
       "      <th>5297</th>\n",
       "      <th>5364</th>\n",
       "      <th>5470</th>\n",
       "      <th>...</th>\n",
       "      <th>28374007</th>\n",
       "      <th>28449207</th>\n",
       "      <th>28458598</th>\n",
       "      <th>28477789</th>\n",
       "      <th>28588345</th>\n",
       "      <th>28597587</th>\n",
       "      <th>28678119</th>\n",
       "      <th>28686840</th>\n",
       "      <th>28763485</th>\n",
       "      <th>28862528</th>\n",
       "      <th>28954189</th>\n",
       "      <th>28962906</th>\n",
       "      <th>29008738</th>\n",
       "      <th>29056083</th>\n",
       "      <th>29069989</th>\n",
       "      <th>29236299</th>\n",
       "      <th>29237211</th>\n",
       "      <th>29283884</th>\n",
       "      <th>29367958</th>\n",
       "      <th>29385546</th>\n",
       "      <th>29396738</th>\n",
       "      <th>29519514</th>\n",
       "      <th>29519517</th>\n",
       "      <th>29541818</th>\n",
       "      <th>29610595</th>\n",
       "      <th>29772863</th>\n",
       "      <th>29780253</th>\n",
       "      <th>29868610</th>\n",
       "      <th>29939230</th>\n",
       "      <th>29939390</th>\n",
       "      <th>29991719</th>\n",
       "      <th>30075802</th>\n",
       "      <th>30095464</th>\n",
       "      <th>30117284</th>\n",
       "      <th>30226723</th>\n",
       "      <th>30253864</th>\n",
       "      <th>30256248</th>\n",
       "      <th>30312891</th>\n",
       "      <th>30555488</th>\n",
       "      <th>30653853</th>\n",
       "      <th>30724132</th>\n",
       "      <th>31140847</th>\n",
       "      <th>31450852</th>\n",
       "      <th>31451174</th>\n",
       "      <th>31931941</th>\n",
       "      <th>32075662</th>\n",
       "      <th>32075671</th>\n",
       "      <th>32571395</th>\n",
       "      <th>33232571</th>\n",
       "      <th>35247769</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00238d8a4c276c47f5d5e242f54a8f28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002a023d3de233b4bd3ec4fc3e9c581a</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006f552534b15a7358a125f7505e0eea</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009235f414f42cfd0f76282f6aefe6c1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009a47e49c0dc6e84d1c5e0eb4cdf7f6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00b5b129cc3cfa6511418cce1cec54ab</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01001347e5bab7241212a0a6910260f8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0102db8db2097cd4482ebc20b7b2d5be</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0118d9d0a565b11b7ff9edcaace80f75</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01546af41b83c0b4141b11c19e8c35af</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1276 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id                           1         2         3         5         \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       5.0       5.0   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           6         11        34        830       \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       4.0       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       4.0   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           865       890       902       930       \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       4.0       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       4.0   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           960       968       1103      1232      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       5.0       4.0   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       2.0       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           1617      1618      1622      1845      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       5.0       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       3.0       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           1885      1934      1953      2156      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       3.0       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           2165      2187      2493      2526      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       4.0       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       3.0   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           2623      2657      2744      2839      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           2998      3431      3473      3636      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       4.0   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       5.0   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           3682      4214      4381      4407      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           4588      4671      4929      4981      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       5.0       4.0       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           5043      5107      5129      5297      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       5.0   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           5364      5470      ...  28374007  28449207  \\\n",
       "user_id                                               ...                       \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN  ...       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN  ...       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN  ...       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN  ...       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN  ...       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       5.0  ...       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN  ...       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN  ...       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN  ...       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN  ...       NaN       NaN   \n",
       "\n",
       "book_id                           28458598  28477789  28588345  28597587  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           28678119  28686840  28763485  28862528  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       5.0       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           28954189  28962906  29008738  29056083  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       5.0   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       1.0   \n",
       "009235f414f42cfd0f76282f6aefe6c1       5.0       4.0       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           29069989  29236299  29237211  29283884  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           29367958  29385546  29396738  29519514  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       5.0       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       5.0   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           29519517  29541818  29610595  29772863  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       4.0       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       4.0       NaN       NaN   \n",
       "\n",
       "book_id                           29780253  29868610  29939230  29939390  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       5.0       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           29991719  30075802  30095464  30117284  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       5.0       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           30226723  30253864  30256248  30312891  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       4.0       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       4.0       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           30555488  30653853  30724132  31140847  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       3.0       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       4.0       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       3.0       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           31450852  31451174  31931941  32075662  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       5.0   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN   \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN   \n",
       "0102db8db2097cd4482ebc20b7b2d5be       NaN       NaN       NaN       NaN   \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN   \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           32075671  32571395  33232571  35247769  \n",
       "user_id                                                                   \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN  \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN  \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN  \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       5.0       NaN  \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN  \n",
       "00b5b129cc3cfa6511418cce1cec54ab       NaN       NaN       NaN       NaN  \n",
       "01001347e5bab7241212a0a6910260f8       NaN       NaN       NaN       NaN  \n",
       "0102db8db2097cd4482ebc20b7b2d5be       5.0       NaN       NaN       NaN  \n",
       "0118d9d0a565b11b7ff9edcaace80f75       NaN       NaN       NaN       NaN  \n",
       "01546af41b83c0b4141b11c19e8c35af       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[10 rows x 1276 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.pivot_table(df, columns=\"book_id\", index=\"user_id\", values=\"rating\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vobennKxqBXx",
    "outputId": "06e3fbe8-de72-4a1c-9ffa-f9c629c4ff4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1218, 1276)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHSkO2aLmqL9",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Convert to an array to work with the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "idzyac1lmqL9",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "a61a4ff4-62e9-419e-fcf1-3988e3d36549",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>book_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>11</th>\n",
       "      <th>34</th>\n",
       "      <th>830</th>\n",
       "      <th>865</th>\n",
       "      <th>890</th>\n",
       "      <th>902</th>\n",
       "      <th>930</th>\n",
       "      <th>960</th>\n",
       "      <th>968</th>\n",
       "      <th>1103</th>\n",
       "      <th>1232</th>\n",
       "      <th>1617</th>\n",
       "      <th>1618</th>\n",
       "      <th>1622</th>\n",
       "      <th>1845</th>\n",
       "      <th>1885</th>\n",
       "      <th>1934</th>\n",
       "      <th>1953</th>\n",
       "      <th>2156</th>\n",
       "      <th>2165</th>\n",
       "      <th>2187</th>\n",
       "      <th>2493</th>\n",
       "      <th>2526</th>\n",
       "      <th>2623</th>\n",
       "      <th>2657</th>\n",
       "      <th>2744</th>\n",
       "      <th>2839</th>\n",
       "      <th>2998</th>\n",
       "      <th>3431</th>\n",
       "      <th>3473</th>\n",
       "      <th>3636</th>\n",
       "      <th>3682</th>\n",
       "      <th>4214</th>\n",
       "      <th>4381</th>\n",
       "      <th>4407</th>\n",
       "      <th>4588</th>\n",
       "      <th>4671</th>\n",
       "      <th>4929</th>\n",
       "      <th>4981</th>\n",
       "      <th>5043</th>\n",
       "      <th>5107</th>\n",
       "      <th>5129</th>\n",
       "      <th>5297</th>\n",
       "      <th>5364</th>\n",
       "      <th>5470</th>\n",
       "      <th>...</th>\n",
       "      <th>28374007</th>\n",
       "      <th>28449207</th>\n",
       "      <th>28458598</th>\n",
       "      <th>28477789</th>\n",
       "      <th>28588345</th>\n",
       "      <th>28597587</th>\n",
       "      <th>28678119</th>\n",
       "      <th>28686840</th>\n",
       "      <th>28763485</th>\n",
       "      <th>28862528</th>\n",
       "      <th>28954189</th>\n",
       "      <th>28962906</th>\n",
       "      <th>29008738</th>\n",
       "      <th>29056083</th>\n",
       "      <th>29069989</th>\n",
       "      <th>29236299</th>\n",
       "      <th>29237211</th>\n",
       "      <th>29283884</th>\n",
       "      <th>29367958</th>\n",
       "      <th>29385546</th>\n",
       "      <th>29396738</th>\n",
       "      <th>29519514</th>\n",
       "      <th>29519517</th>\n",
       "      <th>29541818</th>\n",
       "      <th>29610595</th>\n",
       "      <th>29772863</th>\n",
       "      <th>29780253</th>\n",
       "      <th>29868610</th>\n",
       "      <th>29939230</th>\n",
       "      <th>29939390</th>\n",
       "      <th>29991719</th>\n",
       "      <th>30075802</th>\n",
       "      <th>30095464</th>\n",
       "      <th>30117284</th>\n",
       "      <th>30226723</th>\n",
       "      <th>30253864</th>\n",
       "      <th>30256248</th>\n",
       "      <th>30312891</th>\n",
       "      <th>30555488</th>\n",
       "      <th>30653853</th>\n",
       "      <th>30724132</th>\n",
       "      <th>31140847</th>\n",
       "      <th>31450852</th>\n",
       "      <th>31451174</th>\n",
       "      <th>31931941</th>\n",
       "      <th>32075662</th>\n",
       "      <th>32075671</th>\n",
       "      <th>32571395</th>\n",
       "      <th>33232571</th>\n",
       "      <th>35247769</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00238d8a4c276c47f5d5e242f54a8f28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002a023d3de233b4bd3ec4fc3e9c581a</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006f552534b15a7358a125f7505e0eea</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009235f414f42cfd0f76282f6aefe6c1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>009a47e49c0dc6e84d1c5e0eb4cdf7f6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbf525357e96614c4b9ee613aa95caa</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd6c966d94d3d06c8cc4480536082b4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd8f0635d15905b37ae3ab6743af80c</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff3a250fbc018ad2c2c2d45c86734da</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffff7cafdaf5196383cb2efca08fb6fe</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1218 rows × 1276 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "book_id                           1         2         3         5         \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       5.0       5.0   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       2.0       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       5.0       NaN       NaN   \n",
       "\n",
       "book_id                           6         11        34        830       \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       4.0       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           865       890       902       930       \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       4.0       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       5.0       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           960       968       1103      1232      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       5.0       4.0   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           1617      1618      1622      1845      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       5.0       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       5.0       NaN       NaN       4.0   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           1885      1934      1953      2156      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           2165      2187      2493      2526      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       4.0       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           2623      2657      2744      2839      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           2998      3431      3473      3636      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       4.0   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       2.0   \n",
       "\n",
       "book_id                           3682      4214      4381      4407      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       2.0       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           4588      4671      4929      4981      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       1.0       NaN       2.0   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           5043      5107      5129      5297      \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           5364      5470      ...  28374007  28449207  \\\n",
       "user_id                                               ...                       \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN  ...       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN  ...       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN  ...       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN  ...       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN  ...       NaN       NaN   \n",
       "...                                    ...       ...  ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN  ...       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN  ...       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN  ...       NaN       5.0   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN  ...       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN  ...       NaN       NaN   \n",
       "\n",
       "book_id                           28458598  28477789  28588345  28597587  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       3.0       NaN       3.0       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           28678119  28686840  28763485  28862528  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       5.0   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           28954189  28962906  29008738  29056083  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       5.0   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       1.0   \n",
       "009235f414f42cfd0f76282f6aefe6c1       5.0       4.0       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       2.0       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           29069989  29236299  29237211  29283884  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           29367958  29385546  29396738  29519514  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       5.0       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       2.0       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           29519517  29541818  29610595  29772863  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           29780253  29868610  29939230  29939390  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       5.0       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       5.0       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           29991719  30075802  30095464  30117284  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       5.0       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           30226723  30253864  30256248  30312891  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       0.0   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           30555488  30653853  30724132  31140847  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       3.0       NaN       NaN       NaN   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           31450852  31451174  31931941  32075662  \\\n",
       "user_id                                                                    \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN   \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN   \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN   \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       NaN       5.0   \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN   \n",
       "...                                    ...       ...       ...       ...   \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN   \n",
       "ffd6c966d94d3d06c8cc4480536082b4       NaN       NaN       NaN       NaN   \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN   \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN   \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       NaN       NaN       NaN   \n",
       "\n",
       "book_id                           32075671  32571395  33232571  35247769  \n",
       "user_id                                                                   \n",
       "00238d8a4c276c47f5d5e242f54a8f28       NaN       NaN       NaN       NaN  \n",
       "002a023d3de233b4bd3ec4fc3e9c581a       NaN       NaN       NaN       NaN  \n",
       "006f552534b15a7358a125f7505e0eea       NaN       NaN       NaN       NaN  \n",
       "009235f414f42cfd0f76282f6aefe6c1       NaN       NaN       5.0       NaN  \n",
       "009a47e49c0dc6e84d1c5e0eb4cdf7f6       NaN       NaN       NaN       NaN  \n",
       "...                                    ...       ...       ...       ...  \n",
       "ffbf525357e96614c4b9ee613aa95caa       NaN       NaN       NaN       NaN  \n",
       "ffd6c966d94d3d06c8cc4480536082b4       5.0       NaN       NaN       NaN  \n",
       "ffd8f0635d15905b37ae3ab6743af80c       NaN       NaN       NaN       NaN  \n",
       "fff3a250fbc018ad2c2c2d45c86734da       NaN       NaN       NaN       NaN  \n",
       "ffff7cafdaf5196383cb2efca08fb6fe       NaN       3.0       NaN       NaN  \n",
       "\n",
       "[1218 rows x 1276 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "va_I-ShImqL9",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "3191534b-a087-4b45-da4f-c389d2cdad27",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan  5. nan ...  3. nan nan]]\n"
     ]
    }
   ],
   "source": [
    "data_matrix = df.to_numpy(na_value=np.nan)\n",
    "print(data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khOoAYeMmqL9",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "dd466c19-a792-4af1-c922-67ddb11cf4a5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   65]\n",
      " [   0   79]\n",
      " [   0  204]\n",
      " ...\n",
      " [1217 1223]\n",
      " [1217 1236]\n",
      " [1217 1273]]\n"
     ]
    }
   ],
   "source": [
    "# Check how to get the index of not empty values\n",
    "idx = np.argwhere(~np.isnan(data_matrix))\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4i6vLKb_mqL-",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "151c840c-b9dd-4ae5-85a3-0895f3c73b5b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data_matrix[idx[:,0], idx[:,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKX1GoN3vcYY"
   },
   "source": [
    "# Frank-Wolfe - standard algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sK9kPumvmqL-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Should we feed $\\delta$ to the FW algorithm or should it be defined based on the dimensions of the data?\n",
    "- Which is the correct objective function?\n",
    "- Initialize with random matrix of integers from 1 to 5 or with zeros matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igJ95M7EmqL-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kNN3FZyamqL_",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "kobsOmgimqL_",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def FW_objective_function(diff_vec):\n",
    "    return 0.5*(np.power(diff_vec,2).sum())\n",
    "    #return 0.5 * np.linalg.norm(diff_vec, 2)**2\n",
    "\n",
    "def FrankWolfe(X, objective_function, delta, printing_res = True, Z_init = None, max_iter = 150, patience = 1e-3):\n",
    "    '''\n",
    "    :param X: sparse matrix with ratings and 'empty values', rows - users, columns - books.\n",
    "    :param objective_function: objective function that we would like to minimize with FW\n",
    "    :param Z_init: In case we want to initialize Z with a known matrix, if not given Z_init will be a zeros matrix\n",
    "    :param max_iter: max number of iterations for the method\n",
    "    :param patience: once reached this tolerance provide the result\n",
    "    :return: Z: matrix of predicted ratings - it should be like X but with no 'empty values'\n",
    "            accuracy: difference between original values (X) and predicted ones (Z)\n",
    "    '''\n",
    "    res_list = []\n",
    "\n",
    "    # Get X indexes for not empty values\n",
    "    idx_ratings = np.argwhere(X != 0)\n",
    "    #idx_ratings = np.argwhere(~np.isnan(X))\n",
    "    idx_rows = idx_ratings[:,0]\n",
    "    idx_cols = idx_ratings[:,1]\n",
    "\n",
    "    # Initialize Z -- think about a good init\n",
    "    if Z_init is not None:\n",
    "        Z = Z_init\n",
    "    else:\n",
    "        #Z = np.random.randint(1, 6, size=X.shape)\n",
    "        #Z = Z.astype(float)\n",
    "        Z = np.random.uniform(low = 0.01, high = 1, size = X.shape)\n",
    "\n",
    "    # Create vectors with the not empty features of the sparse matrix\n",
    "    X_rated = X[idx_rows, idx_cols]\n",
    "    Z_rated = Z[idx_rows, idx_cols]\n",
    "    diff_vec = Z_rated - X_rated\n",
    "\n",
    "    # choose an appropriate delta\n",
    "    delta = delta\n",
    "\n",
    "    diff_err = patience + 1\n",
    "    err = objective_function(diff_vec)\n",
    "    it = 0\n",
    "    while (diff_err > patience) and (it < max_iter):\n",
    "\n",
    "        # Gradient\n",
    "        grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "\n",
    "        # SVD\n",
    "        u_max, s_max, v_max = sparse.linalg.svds(grad, k = 1, which='LM')   # Compute k = 1 singular values, starting from the largest (which = 'LM')\n",
    "\n",
    "        # Update\n",
    "        Zk_tilde = -delta*np.outer(u_max,v_max)     # Zk_tilde in the theory\n",
    "        #Zk_tilde = np.random.uniform(size = Z.shape)\n",
    "        #alpha - as studied in class\n",
    "        alpha_k = 2/(it+2)\n",
    "        Z = (1-alpha_k)*Z + alpha_k*Zk_tilde\n",
    "        # Error\n",
    "        diff_vec = Z[idx_rows, idx_cols] - X_rated\n",
    "        new_err = objective_function(diff_vec)\n",
    "\n",
    "        # Improvement at this iteration\n",
    "        diff_err = np.abs(err - new_err)\n",
    "        err = new_err\n",
    "\n",
    "        if printing_res == True:\n",
    "            if it == 1 or it % 10 == 0:\n",
    "                print('Iteration:', it, 'Err:', err, 'Diff err:', diff_err, 'Z rank: ',sparse.csgraph.structural_rank(Z), 'Z_tilde rank: ', sparse.csgraph.structural_rank(Zk_tilde) )\n",
    "                \n",
    "\n",
    "        # Count iteration\n",
    "        it += 1\n",
    "\n",
    "        res_list.append(err)\n",
    "        \n",
    "    return Z, Zk_tilde, err, res_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXTeGA9emqMA",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We build a smaller matrix for testing the FW alg, then we will apply it to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "8_5BaHGfmqMA",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 400)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "flatten() got an unexpected keyword argument 'inplace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-5808991e3719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mdiff_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ_rated\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_rated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mflattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: flatten() got an unexpected keyword argument 'inplace'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "  \n",
    "n = 400\n",
    "m = 200\n",
    "r = 10\n",
    "rho = 0.10\n",
    "SNR = 5\n",
    "delta = 3.75\n",
    "\n",
    "\n",
    "\n",
    "# taking data\n",
    "U = scipy.sparse.random(m, r, density=0.1, format='csr', data_rvs=None)\n",
    "V = scipy.sparse.random(r, n, density=0.1, format='csr', data_rvs=None)\n",
    "E = scipy.sparse.random(m, n, density=0.1, format='csr', data_rvs=None)\n",
    "\n",
    "\n",
    "\n",
    "VT = V.transpose(copy=True)\n",
    "\n",
    "UVT = U*V\n",
    "print(UVT. shape)\n",
    "\n",
    "w1 = 1/(scipy.sparse.linalg.norm(UVT, ord='fro'))\n",
    "\n",
    "w2 = 1/(SNR*scipy.sparse.linalg.norm(E, ord='fro'))\n",
    "\n",
    "\n",
    "#Finally observed data matrix is: \n",
    "\n",
    "X = w1*UVT + w2*E\n",
    "\n",
    "\n",
    "idx_ratings = np.argwhere(X != 0)\n",
    "    #idx_ratings = np.argwhere(~np.isnan(X))\n",
    "idx_rows = idx_ratings[:,0]\n",
    "idx_cols = idx_ratings[:,1]\n",
    "\n",
    "\n",
    "Z = np.random.uniform(low = 0.01, high = 1, size = X.shape)\n",
    "\n",
    "    # Create vectors with the not empty features of the sparse matrix\n",
    "X_rated = X[idx_rows, idx_cols]\n",
    "Z_rated = Z[idx_rows, idx_cols]\n",
    "diff_vec = Z_rated - X_rated\n",
    "\n",
    "flattened = diff_vec.T.flatten()\n",
    "\n",
    "print(flattened.shape)\n",
    "\n",
    "print(idx_rows.shape)\n",
    "print(idx_cols.shape)\n",
    "\n",
    "\n",
    "#print(np.linalg.matrix_rank(X))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "grad = sparse.csr_matrix((flattened, (idx_rows, idx_cols)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "HiCoSkpMmqMA",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "row, column, and data array must all be the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-37fe9470378a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrankWolfe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFW_objective_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-2d4d803154d5>\u001b[0m in \u001b[0;36mFrankWolfe\u001b[0;34m(X, objective_function, delta, printing_res, Z_init, max_iter, patience)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     52\u001b[0m                     \u001b[0;31m# (data, ij) format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     other = self.__class__(coo_matrix(arg1, shape=shape,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                                       dtype=dtype))\n\u001b[1;32m     56\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36m_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_native\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnnz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'row index exceeds matrix dimensions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mnnz\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mcount_nonzero\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mNumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mzero\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mgetnnz\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mnnz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnnz\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnnz\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 raise ValueError('row, column, and data array must all be the '\n\u001b[0m\u001b[1;32m    244\u001b[0m                                  'same length')\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: row, column, and data array must all be the same length"
     ]
    }
   ],
   "source": [
    "pred_ratings, loss = FrankWolfe(new_data, FW_objective_function, delta = 3.75, max_iter=100, patience=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "SP5L59OqmqMA",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#pred_ratings*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "TFmkDoxPmqMA",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# idx_ratings = np.argwhere(~np.isnan(X_test))\n",
    "# idx_rows = idx_ratings[:,0]\n",
    "# idx_cols = idx_ratings[:,1]\n",
    "# pred_ratings[idx_rows,idx_cols]*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0Cx8xFtmqMB",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Our data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "kvTz-usn3I0b"
   },
   "outputs": [],
   "source": [
    "new_data = np.nan_to_num(data_matrix, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9mDrB5PmqMB",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "8d126b0e-35a7-45bb-88d0-b5f76cd3cd9f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.2700752 0.2700752 0.2700752 ... 0.2700752 0.2700752 0.2700752].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-3d2c5ba98be5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_ratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_Z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_listFW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrankWolfe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFW_objective_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m44000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-234-80c263504118>\u001b[0m in \u001b[0;36mFrankWolfe\u001b[0;34m(X, objective_function, delta, printing_res, Z_init, max_iter, patience)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0msvd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Compute k = 1 singular values, starting from the largest (which = 'LM')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mu_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;31m# Update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mZk_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv_max\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Zk_tilde in the theory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/decomposition/_truncated_svd.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \"\"\"\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/decomposition/_truncated_svd.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mReduced\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mof\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0mwill\u001b[0m \u001b[0malways\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdense\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    762\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.2700752 0.2700752 0.2700752 ... 0.2700752 0.2700752 0.2700752].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "pred_ratings, update_Z, loss, res_listFW = FrankWolfe(new_data, FW_objective_function, delta = 44000, max_iter=25, patience=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "0v5KuYLNkkhK"
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "HZ32fVy_kiWd",
    "outputId": "5b18413e-dcd1-4941-fac8-9061fb7679d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc81b480df0>]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(res_listFW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1218\n",
      "[[186.84049249 191.51075278 161.30923878 ... 231.81278875 218.73175139\n",
      "  223.229082  ]\n",
      " [188.75780771 193.47574377 162.96590817 ... 234.18920809 220.97463801\n",
      "  225.51787651]\n",
      " [209.97759916 215.22318453 181.30101461 ... 260.49011219 245.79767516\n",
      "  250.84899698]\n",
      " ...\n",
      " [178.97089452 183.44547087 154.50945294 ... 222.05881144 209.52585602\n",
      "  213.8347586 ]\n",
      " [192.2248474  197.02898913 165.96166956 ... 238.48637445 225.03035193\n",
      "  229.65660187]\n",
      " [177.67842658 182.12086987 153.39264576 ... 220.45692064 208.01396828\n",
      "  212.29192698]]\n"
     ]
    }
   ],
   "source": [
    "pred_reg = (pred_ratings*6)-1\n",
    "\n",
    "print(np.linalg.matrix_rank(pred_reg, tol = -10))\n",
    "print(pred_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y-VOlLMvfq8"
   },
   "source": [
    "# Frank-Wolfe In-face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ohhjqLXgcoRt"
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import time \n",
    "\n",
    "time_out = time.process_time() + 5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "bRpuyws1mqMB",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def FW_objective_function(diff_vec):\n",
    "    return 0.5*(np.power(diff_vec,2).sum())\n",
    "    #return 0.5 * np.linalg.norm(diff_vec, 2)**2\n",
    "    \n",
    "def alpha_binary_search(Zk, Dk, delta, max_value = 1, min_value = 0, tol = 0.3):\n",
    "        \n",
    "    #Inizialization\n",
    "    \n",
    "    best_alpha = (max_value - min_value) / 2\n",
    "    \n",
    "    testing_matrix = Zk + best_alpha * Dk\n",
    "\n",
    "    sentinel = False\n",
    "\n",
    "    while time.process_time() <= time_out:\n",
    "      \n",
    "      testing_mat_nuclear_norm = LA.norm(testing_matrix, ord = 'nuc')\n",
    "\n",
    "      sentinel = True\n",
    "    \n",
    "    #Binary Search\n",
    "\n",
    "    if sentinel == True:\n",
    "    \n",
    "      while testing_mat_nuclear_norm <= delta and (max_value - min_value) >= tol and time.process_time() <= time_out:\n",
    "          \n",
    "          min_value = best_alpha\n",
    "          \n",
    "          best_alpha = (max_value - min_value) / 2\n",
    "\n",
    "          testing_matrix = Zk + best_alpha * Dk\n",
    "      \n",
    "          testing_mat_nuclear_norm = LA.norm(testing_matrix, ord = 'nuc')     \n",
    "        \n",
    "    return best_alpha\n",
    "\n",
    "def FW_inface(X, objective_function, delta, gamma1 = 0, gamma2 = 1, THRES = 0.001, Z_init = None, max_iter=150, patience=1e-3, printing = True):\n",
    "    '''\n",
    "    :param X: sparse matrix with ratings and 'empty values', rows - users, columns - books.\n",
    "    :param objective_function: objective function that we would like to minimize with FW.\n",
    "    :param Z_init: In case we want to initialize Z with a known matrix, if not given Z_init will be a zeros matrix.\n",
    "    :param max_iter: max number of iterations for the method.\n",
    "    :param patience: once reached this tolerance provide the result.\n",
    "    :return: Z: matrix of predicted ratings - it should be like X but with no 'empty values'\n",
    "            loss: difference between original values (X) and predicted ones (Z).\n",
    "    '''\n",
    "\n",
    "    # Get X indexes for not empty values\n",
    "    idx_ratings = np.argwhere(X != 0)\n",
    "    #idx_ratings = np.argwhere(~np.isnan(X))\n",
    "    idx_rows = idx_ratings[:,0]\n",
    "    idx_cols = idx_ratings[:,1]\n",
    "\n",
    "    # choose an appropriate delta\n",
    "\n",
    "    # Initialize Z_{-1}\n",
    "    if Z_init is not None:\n",
    "        Z = Z_init\n",
    "    else:\n",
    "        Z = np.zeros(X.shape)\n",
    "\n",
    "    # Create vectors with the not empty features of the sparse matrix\n",
    "    X_rated = X[idx_rows, idx_cols]\n",
    "    Z_rated = Z[idx_rows, idx_cols]\n",
    "    diff_vec = Z_rated - X_rated\n",
    "\n",
    "    # Initial gradient and Z0\n",
    "    grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "    u_max, s_max, v_max = sparse.linalg.svds(grad, k = 1, which='LM')\n",
    "    Z = -delta*np.outer(u_max,v_max)\n",
    "    Z_rated = Z[idx_rows, idx_cols]\n",
    "\n",
    "    # Initialize lower bound on the optimal objective function (f*)\n",
    "    diff_vec = Z_rated - X_rated\n",
    "    new_low_bound = np.max((objective_function(diff_vec) + np.multiply(diff_vec,Z_rated)),0)\n",
    "\n",
    "    # Set L and D constants and gamma1, gamma2 constraints\n",
    "    L = 1\n",
    "    D = 2*delta\n",
    "\n",
    "    # Compute first iteration thin SVD\n",
    "    grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "    r_grad = sparse.csgraph.structural_rank(grad)   # Compute rank of the gradient sparse matrix to find thin SVD size\n",
    "    print(r_grad, grad.shape)\n",
    "    # U_thin, D_thin, Vh_thin = sparse.linalg.svds(grad, k = r_grad, which = 'LM')   # Compute k = rank singular values # replaced r_grad with 1\n",
    "    # U_app, D_app, Vh_app = sparse.linalg.svds(grad, k = 1, which='SM')\n",
    "    U_thin, D_thin, Vh_thin = LA.svd(grad.toarray())\n",
    "    D_thin = D_thin.T\n",
    "\n",
    "    # Additional needed parameters\n",
    "    diff_objective = patience + 1\n",
    "    objective = objective_function(diff_vec)\n",
    "    it = 0\n",
    "    while (diff_objective > patience) and (it < max_iter):\n",
    "\n",
    "        # Lower bound update\n",
    "        low_bound = new_low_bound\n",
    "\n",
    "        # In-face direction with the away step strategy: two calculations depending of where Z lies within the feasible set\n",
    "        if D_thin.sum() == delta: # Z in border (sum of singular values == radious of feasible set)\n",
    "            G = 0.5(Vh_thin.dot(grad.T.dot(U_thin)) + U_thin.T.dot(grad.dot(Vh_thin.T)))\n",
    "            u = sparse.linalg.eigs(G, k = 1, which = 'SM')#unitary eigenvector corresponding to smallest eigenvalue of G\n",
    "            M = np.outer(u,u)\n",
    "            update_Z = delta*U_thin.dot(M.dot(Vh_thin))  # Zk tilde, right?\n",
    "            update_direction = Z-update_Z\n",
    "            alpha_B = scipy.linalg.inv(delta*u.T.dot(scipy.linalg.inv(update_direction).dot(u))-1)\n",
    "            \n",
    "        else: #inside\n",
    "\n",
    "            idx_max_s = np.argmax(D_thin)\n",
    "            update_Z = delta*np.outer(U_thin[idx_max_s,:],Vh_thin[idx_max_s,:])\n",
    "            update_direction = Z-update_Z\n",
    "            #BINARY SEARCH (xd)\n",
    "            alpha_B = alpha_binary_search(Z, # This one should be Zk, not Zk tilde... have I chose the correct variable? \n",
    "                                          D_thin, # This one should be the direction matrix\n",
    "                                          delta) \n",
    "\n",
    "        nuclear_norm = D_thin.sum()\n",
    "        U = nuclear_norm*D_thin # standardize the simplex\n",
    "        r = D_thin.shape[0]     # added the index so it could be compared to a number\n",
    "        no_obs = idx_rows.shape[0]\n",
    "        # THRES = 0.001\n",
    "        \n",
    "        if abs(delta - nuclear_norm) < THRES and r > 1:\n",
    "            Z_B = Z + alpha_B*update_direction\n",
    "            diff_vec_B = Z_B[idx_rows, idx_cols] - X_rated\n",
    "            beta = 0.5 # FIND A GOOD VALUE -- a binary search is also suggested by the paper xdd\n",
    "            Z_A = Z + beta*update_direction\n",
    "            diff_vec_A = Z_A[idx_rows, idx_cols] - X_rated\n",
    "            \n",
    "            if 1/(objective_function(diff_vec_B)-low_bound) >= (1/(objective-low_bound)+gamma1/(2*L*D**2)):\n",
    "              # 1. Move to a lower dimensional face\n",
    "              print('Went to a lower-dimensional face')\n",
    "              Z = Z_B\n",
    "              \n",
    "              #SHOULDN'T THIS BE THE SAME AS THE DENOMINATOR IN THE INEQUALITY CHECK? SEE RED CIRCLES IN IMAGE\n",
    "\n",
    "            else:\n",
    "                beta = 0.5 # FIND A GOOD VALUE -- a binary search is also suggested by the paper xdd\n",
    "                Z_A = Z + beta*update_direction\n",
    "                diff_vec_A = Z_A[idx_rows, idx_cols] - X_rated\n",
    "\n",
    "\n",
    "            if 1/(objective_function(diff_vec_A)-low_bound) >= (1/(objective-low_bound)+gamma2/(2*L*D**2)):\n",
    "                # 2. Stay in the current face\n",
    "                print('Stay in the current face')\n",
    "                Z = Z_A\n",
    "                #SHOULDN'T THIS BE THE SAME AS THE DENOMINATOR IN THE INEQUALITY CHECK? SEE RED CIRCLES IN IMAGE\n",
    "\n",
    "        else:\n",
    "\n",
    "            # 3. Do a regular FW step and update the lower bound\n",
    "            print('Do regular FW step')\n",
    "            #Zk update\n",
    "            idx_max_s = np.argmax(D_thin)\n",
    "            update_Z = -delta*np.outer(U_thin[idx_max_s,:],Vh_thin[:,idx_max_s]) # Am i selecting right the vectors??\n",
    "            alpha_k = 2/(it+2)\n",
    "            Z = (1-alpha_k)*Z + alpha_k*update_Z\n",
    "\n",
    "            # Lower bound update\n",
    "            direction_vec = update_Z.flatten() - Z.flatten()\n",
    "\n",
    "            grad = grad.toarray() # this method converts the sparse matrix into a numpy array!\n",
    "\n",
    "            wolfe_gap = grad.T.flatten() * direction_vec #added the flatten otherwise you can't do the operation\n",
    "            B_w = objective + wolfe_gap.sum()\n",
    "            #new_low_bound = np.max(low_bound, B_w)   # gave problems during the execution: wanted both numbers as integers??\n",
    "\n",
    "            ''' TRIED THIS INSTEAD'''\n",
    "            if low_bound >= B_w:\n",
    "              new_low_bound = low_bound\n",
    "            else:\n",
    "              new_low_bound = B_w\n",
    "            ''' '''\n",
    "\n",
    "        # Loss\n",
    "        diff_vec = Z[idx_rows, idx_cols] - X_rated\n",
    "        new_objective = objective_function(diff_vec)\n",
    "\n",
    "        # Improvement at this iteration\n",
    "        diff_objective = np.abs(objective - new_objective)\n",
    "        objective = new_objective\n",
    "\n",
    "        # Gradient\n",
    "        grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "\n",
    "        # Thin SVD\n",
    "        r_grad = sparse.csgraph.structural_rank(grad)   # Compute rank of the gradient sparse matrix to find thin SVD size\n",
    "        #U_thin, D_thin, Vh_thin = sparse.linalg.svds(grad, k = 1, which='LM')   # Compute k = rank singular values # replaced r_grad with 1\n",
    "        U_thin, D_thin, Vh_thin = LA.svd(grad.toarray())\n",
    "        D_thin = D_thin.T\n",
    "\n",
    "        # Count iteration\n",
    "        it += 1\n",
    "\n",
    "        if printing == True:\n",
    "          if it % 1 == 0 or it == 1:\n",
    "            print('Iteration:', it, 'f(Z_k):', objective, 'f(Z_{k-1}) -f(Z_k):', diff_objective)\n",
    "\n",
    "    return Z, objective, it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "KWhtUsxeKajX"
   },
   "outputs": [],
   "source": [
    "def FW_objective_function(diff_vec):\n",
    "    return 0.5*(np.power(diff_vec,2).sum())\n",
    "    #return 0.5 * np.linalg.norm(diff_vec, 2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "fwNlrgvfKega"
   },
   "outputs": [],
   "source": [
    "def alpha_binary_search(Zk, Dk, delta, max_value = 1, min_value = 0, tol = 0.3):\n",
    "        \n",
    "    #Inizialization\n",
    "    \n",
    "    best_alpha = (max_value - min_value) / 2\n",
    "    \n",
    "    testing_matrix = Zk + best_alpha * Dk\n",
    "\n",
    "    sentinel = False\n",
    "\n",
    "    while time.process_time() <= time_out:\n",
    "      \n",
    "      testing_mat_nuclear_norm = LA.norm(testing_matrix, ord = 'nuc')\n",
    "\n",
    "      sentinel = True\n",
    "    \n",
    "    #Binary Search\n",
    "\n",
    "    if sentinel == True:\n",
    "    \n",
    "      while testing_mat_nuclear_norm <= delta and (max_value - min_value) >= tol and time.process_time() <= time_out:\n",
    "          \n",
    "          min_value = best_alpha\n",
    "          \n",
    "          best_alpha = (max_value - min_value) / 2\n",
    "\n",
    "          testing_matrix = Zk + best_alpha * Dk\n",
    "      \n",
    "          testing_mat_nuclear_norm = LA.norm(testing_matrix, ord = 'nuc')     \n",
    "        \n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9npSHjCjejO4"
   },
   "outputs": [],
   "source": [
    "def FW_inface(X, objective_function, delta, gamma1 = 0, gamma2 = 1, THRES = 0.001, Z_init = None, max_iter=150, patience=1e-3, printing = True):\n",
    "    '''\n",
    "    :param X: sparse matrix with ratings and 'empty values', rows - users, columns - books.\n",
    "    :param objective_function: objective function that we would like to minimize with FW.\n",
    "    :param Z_init: In case we want to initialize Z with a known matrix, if not given Z_init will be a zeros matrix.\n",
    "    :param max_iter: max number of iterations for the method.\n",
    "    :param patience: once reached this tolerance provide the result.\n",
    "    :return: Z: matrix of predicted ratings - it should be like X but with no 'empty values'\n",
    "            loss: difference between original values (X) and predicted ones (Z).\n",
    "    '''\n",
    "\n",
    "    res_list = []\n",
    "\n",
    "    # Get X indexes for not empty values\n",
    "    idx_ratings = np.argwhere(X != 0)\n",
    "    #idx_ratings = np.argwhere(~np.isnan(X))\n",
    "    idx_rows = idx_ratings[:,0]\n",
    "    idx_cols = idx_ratings[:,1]\n",
    "\n",
    "    # choose an appropriate delta\n",
    "\n",
    "    # Initialize Z_{-1}\n",
    "    if Z_init is not None:\n",
    "        Z = Z_init\n",
    "    else:\n",
    "        Z = np.zeros(X.shape)\n",
    "\n",
    "    # Create vectors with the not empty features of the sparse matrix\n",
    "    X_rated = X[idx_rows, idx_cols]\n",
    "    Z_rated = Z[idx_rows, idx_cols]\n",
    "    diff_vec = Z_rated - X_rated\n",
    "\n",
    "    # Initial gradient and Z0\n",
    "    grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "    u_max, s_max, v_max = sparse.linalg.svds(grad, k = 1, which='LM')\n",
    "    Zk = -delta*np.outer(u_max,v_max)\n",
    "    Z_rated = Zk[idx_rows, idx_cols]\n",
    "\n",
    "    # Initialize lower bound on the optimal objective function (f*)\n",
    "    diff_vec = Z_rated - X_rated\n",
    "    #new_low_bound = np.max((objective_function(diff_vec) + np.multiply(diff_vec,Z_rated)), 0)\n",
    "    new_low_bound = 0\n",
    "\n",
    "    # Set L and D constants\n",
    "    L = 1\n",
    "    D = 2*delta\n",
    "\n",
    "    # Compute first iteration thin SVD\n",
    "    #grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "    r_grad = sparse.csgraph.structural_rank(diff_vec)   # Compute rank of the gradient sparse matrix to find thin SVD size\n",
    "    # U_thin, D_thin, Vh_thin = sparse.linalg.svds(grad, k = r_grad, which = 'LM')   # Compute k = rank singular values # replaced r_grad with 1\n",
    "    # U_app, D_app, Vh_app = sparse.linalg.svds(grad, k = 1, which='SM')\n",
    "    U_thin, D_thin, Vh_thin = LA.svd(grad.toarray())\n",
    "    D_thin = D_thin.T\n",
    "\n",
    "    # Additional needed parameters\n",
    "    diff_objective = patience + 1\n",
    "    objective = objective_function(diff_vec)\n",
    "    it = 0\n",
    "\n",
    "    while (diff_objective > patience) and (it < max_iter):\n",
    "\n",
    "        # Lower bound update\n",
    "        low_bound = new_low_bound\n",
    "\n",
    "        # In-face direction with the away step strategy: two calculations depending of where Z lies within the feasible set\n",
    "        if D_thin.sum() == delta: # Z in border (sum of singular values == radious of feasible set)\n",
    "            G = 0.5(Vh_thin.dot(grad.T.dot(U_thin)) + U_thin.T.dot(grad.dot(Vh_thin.T)))\n",
    "            u = sparse.linalg.eigs(G, k = 1, which = 'SM')#unitary eigenvector corresponding to smallest eigenvalue of G\n",
    "            M = np.outer(u,u)\n",
    "            Zk_tilde = delta*U_thin.dot(M.dot(Vh_thin))\n",
    "            Dk = Zk - Zk_tilde\n",
    "            alpha_B = scipy.linalg.inv(delta*u.T.dot(scipy.linalg.inv(Dk).dot(u))-1)\n",
    "            \n",
    "        else: #inside\n",
    "\n",
    "            idx_max_s = np.argmax(D_thin)\n",
    "            Zk_tilde = delta*np.outer(U_thin[idx_max_s,:],Vh_thin[idx_max_s,:])\n",
    "            Dk = Zk - Zk_tilde\n",
    "            #BINARY SEARCH (xd)\n",
    "            alpha_B = alpha_binary_search(Zk, # This one should be Zk, not Zk tilde... have I chose the correct variable? \n",
    "                                          Dk, # This one should be the direction matrix\n",
    "                                          delta) \n",
    "\n",
    "        nuclear_norm = D_thin.sum()\n",
    "        U = nuclear_norm * D_thin # standardize the simplex\n",
    "        r = D_thin.shape[0]     # added the index so it could be compared to a number\n",
    "        no_obs = idx_rows.shape[0]\n",
    "        # THRES = 0.001\n",
    "\n",
    "        #print('Nuclear Norm:  ' + str(nuclear_norm))\n",
    "        \n",
    "        #if abs(delta - nuclear_norm) < THRES and r > 1:\n",
    "        Z_B = Zk + alpha_B * Dk\n",
    "        diff_vec_B = Z_B[idx_rows, idx_cols] - X_rated\n",
    "        beta = alpha_B / 5 # FIND A GOOD VALUE -- a binary search is also suggested by the paper xdd\n",
    "\n",
    "        Z_A = Zk + beta * Dk\n",
    "        diff_vec_A = Z_A[idx_rows, idx_cols] - X_rated\n",
    "\n",
    "        '''\n",
    "\n",
    "        print('First Condition: ' + str(1/(objective_function(diff_vec_B)-low_bound)) + '   vs   Second Condition: ' + str(1/(objective-low_bound)+gamma1/(2*L*D**2)))\n",
    "        print('Elif:')\n",
    "        print('First Condition: ' + str(1/(objective_function(diff_vec_A)-low_bound)) + '   vs   Second Condition: ' + str(1/(objective-low_bound)+gamma2/(2*L*D**2)))\n",
    "\n",
    "        print('Low Bound:' + str(low_bound))\n",
    "        print('1 / (Objective - Low Bound): ' + str(1/(objective-low_bound)))\n",
    "\n",
    "        '''\n",
    "\n",
    "        # if abs(delta - nuclear_norm) < THRES and r > 1:\n",
    "\n",
    "        if 1/(objective_function(diff_vec_B)-low_bound) >= (1/(objective-low_bound)+gamma1/(2*L*D**2)):\n",
    "\n",
    "          # 1. Move to a lower dimensional face\n",
    "          print('Went to a lower-dimensional face')\n",
    "          Zk = Z_B\n",
    "\n",
    "        elif 1/(objective_function(diff_vec_A)-low_bound) >= (1/(objective-low_bound)+gamma2/(2*L*D**2)):\n",
    "\n",
    "          # 2. Stay in the current face\n",
    "          print('Stay in the current face')\n",
    "          Zk = Z_A\n",
    "\n",
    "          # else:\n",
    "          #   raise 'Error'\n",
    "\n",
    "        else:\n",
    "\n",
    "          # 3. Do a regular FW step and update the lower bound\n",
    "          print('Do regular FW step')\n",
    "          \n",
    "          #Zk update\n",
    "          idx_max_s = np.argmax(D_thin)\n",
    "          Zk_tilde = -delta*np.outer(U_thin[idx_max_s,:],Vh_thin[:,idx_max_s]) # Am i selecting right the vectors??\n",
    "          alpha_k = 2/(it+2)\n",
    "          Zk = (1-alpha_k)*Z + alpha_k * Zk_tilde \n",
    "\n",
    "          # Lower bound update\n",
    "          direction_vec = Zk_tilde.flatten() - Zk.flatten()\n",
    "\n",
    "          grad = grad.toarray() # this method converts the sparse matrix into a numpy array!\n",
    "\n",
    "          wolfe_gap = grad.T.flatten() * direction_vec #added the flatten otherwise you can't do the operation\n",
    "          B_w = objective + wolfe_gap.sum()\n",
    "          #new_low_bound = np.max(low_bound, B_w)   # gave problems during the execution: wanted both numbers as integers??\n",
    "\n",
    "          ''' TRIED THIS INSTEAD '''\n",
    "\n",
    "          if low_bound >= B_w:\n",
    "            new_low_bound = low_bound\n",
    "          else:\n",
    "            new_low_bound = B_w\n",
    "          ''' '''\n",
    "\n",
    "        # Loss\n",
    "        diff_vec = Zk[idx_rows, idx_cols] - X_rated\n",
    "        new_objective = objective_function(diff_vec)\n",
    "\n",
    "        # Improvement at this iteration\n",
    "        diff_objective = np.abs(objective - new_objective)\n",
    "        objective = new_objective\n",
    "\n",
    "        # Gradient\n",
    "        grad = sparse.csr_matrix((diff_vec, (idx_rows, idx_cols)))\n",
    "\n",
    "        # Thin SVD\n",
    "        r_grad = sparse.csgraph.structural_rank(grad)   # Compute rank of the gradient sparse matrix to find thin SVD size\n",
    "        #U_thin, D_thin, Vh_thin = sparse.linalg.svds(grad, k = 1, which='LM')   # Compute k = rank singular values # replaced r_grad with 1\n",
    "        U_thin, D_thin, Vh_thin = LA.svd(grad.toarray())\n",
    "        D_thin = D_thin.T\n",
    "\n",
    "        # Count iteration\n",
    "        it += 1\n",
    "\n",
    "        res_list.append(objective)\n",
    "\n",
    "        if printing == True:\n",
    "          if it % 5 == 0 or it == 1:\n",
    "            print('Iteration: ', it, 'f(Z_k): ', objective, 'f(Z_{k-1}) - f(Z_k): ', diff_objective, ' Rank of Zk: ', sparse.csgraph.structural_rank(Zk))\n",
    "            print(''' ''')\n",
    "\n",
    "    return Z, objective, it, res_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwQyN3Cy_uF5"
   },
   "source": [
    "# Tuned Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LYT2WN1_w3C",
    "outputId": "b30a2e18-4097-49e8-e02f-63cf156b227a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: SparseEfficiencyWarning: Input matrix should be in CSC, CSR, or COO matrix format\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Went to a lower-dimensional face\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:181: SparseEfficiencyWarning: Input matrix should be in CSC, CSR, or COO matrix format\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1 f(Z_k):  609443.3405929218 f(Z_{k-1}) - f(Z_k):  77481.73682131304  Rank of Zk:  1218\n",
      " \n",
      "Went to a lower-dimensional face\n",
      "Went to a lower-dimensional face\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Iteration:  5 f(Z_k):  899067.4975256249 f(Z_{k-1}) - f(Z_k):  254.53762226132676  Rank of Zk:  1218\n",
      " \n",
      "Do regular FW step\n",
      "Went to a lower-dimensional face\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Went to a lower-dimensional face\n",
      "Iteration:  10 f(Z_k):  901610.9337171225 f(Z_{k-1}) - f(Z_k):  3227.6742062630365  Rank of Zk:  1218\n",
      " \n",
      "Do regular FW step\n",
      "Went to a lower-dimensional face\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Went to a lower-dimensional face\n",
      "Iteration:  15 f(Z_k):  903922.3702006602 f(Z_{k-1}) - f(Z_k):  6161.866981818457  Rank of Zk:  1218\n",
      " \n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Went to a lower-dimensional face\n",
      "Iteration:  20 f(Z_k):  903300.3752879112 f(Z_{k-1}) - f(Z_k):  5993.132773655001  Rank of Zk:  1218\n",
      " \n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Went to a lower-dimensional face\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Iteration:  25 f(Z_k):  898012.7517477227 f(Z_{k-1}) - f(Z_k):  139.77260386012495  Rank of Zk:  1218\n",
      " \n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Iteration:  30 f(Z_k):  897909.1969472286 f(Z_{k-1}) - f(Z_k):  118.76985743211117  Rank of Zk:  1218\n",
      " \n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Iteration:  35 f(Z_k):  897940.9973018705 f(Z_{k-1}) - f(Z_k):  81.58034098136704  Rank of Zk:  1218\n",
      " \n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Iteration:  40 f(Z_k):  898032.9815604656 f(Z_{k-1}) - f(Z_k):  18.520204829517752  Rank of Zk:  1218\n",
      " \n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Iteration:  45 f(Z_k):  898074.0752795432 f(Z_{k-1}) - f(Z_k):  13.94618788396474  Rank of Zk:  1218\n",
      " \n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Iteration:  50 f(Z_k):  897065.8900803693 f(Z_{k-1}) - f(Z_k):  614.0891759393271  Rank of Zk:  1218\n",
      " \n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Iteration:  55 f(Z_k):  897779.6039525118 f(Z_{k-1}) - f(Z_k):  32.694961685920134  Rank of Zk:  1218\n",
      " \n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Iteration:  60 f(Z_k):  897112.520097295 f(Z_{k-1}) - f(Z_k):  692.0908673102967  Rank of Zk:  1218\n",
      " \n",
      "Went to a lower-dimensional face\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Iteration:  65 f(Z_k):  898043.4526178291 f(Z_{k-1}) - f(Z_k):  553.8807461180259  Rank of Zk:  1218\n",
      " \n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Iteration:  70 f(Z_k):  898047.375537868 f(Z_{k-1}) - f(Z_k):  376.10038021800574  Rank of Zk:  1218\n",
      " \n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Iteration:  75 f(Z_k):  897886.6151504426 f(Z_{k-1}) - f(Z_k):  152.85104373458307  Rank of Zk:  1218\n",
      " \n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Iteration:  80 f(Z_k):  898034.9316655745 f(Z_{k-1}) - f(Z_k):  1129.8311733826995  Rank of Zk:  1218\n",
      " \n",
      "Stay in the current face\n",
      "Went to a lower-dimensional face\n",
      "Do regular FW step\n",
      "Went to a lower-dimensional face\n",
      "Do regular FW step\n",
      "Iteration:  85 f(Z_k):  898039.219876508 f(Z_{k-1}) - f(Z_k):  464.6649295502575  Rank of Zk:  1218\n",
      " \n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Iteration:  90 f(Z_k):  898046.4707782301 f(Z_{k-1}) - f(Z_k):  232.66333428793587  Rank of Zk:  1218\n",
      " \n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Do regular FW step\n",
      "Iteration:  95 f(Z_k):  898043.8808805925 f(Z_{k-1}) - f(Z_k):  0.24954904185142368  Rank of Zk:  1218\n",
      " \n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Stay in the current face\n",
      "Do regular FW step\n",
      "Stay in the current face\n",
      "Iteration:  100 f(Z_k):  897562.910004704 f(Z_{k-1}) - f(Z_k):  476.4715212463634  Rank of Zk:  1218\n",
      " \n"
     ]
    }
   ],
   "source": [
    "pred_ratings, loss, it, res_listInFW = FW_inface(new_data, FW_objective_function, gamma1 = 0, gamma2 = 1, delta = 500, THRES = 10000, max_iter = 100, patience = 0.0001, printing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "aRRdiMfomX34",
    "outputId": "2efe67f6-7a38-4192-9b8e-755860d3040d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(res_listFW, label = 'Frank Wolfe')\n",
    "plt.plot(res_listInFW, label = 'In-Face Frank Wolfe')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0manG1buepT"
   },
   "source": [
    "# Grid Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_MUb9nrwJyA"
   },
   "source": [
    "##Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUZGgSUsudah",
    "outputId": "bd7fb5f1-3a5b-4467-e5cc-23f3784569fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 0.001    ------     Final Loss: 1995299.6906607011   at iteration 2\n",
      "Delta: 0.01    ------     Final Loss: 1995296.9066038157   at iteration 2\n",
      "Delta: 0.1    ------     Final Loss: 1995269.065718345   at iteration 2\n",
      "Delta: 1    ------     Final Loss: 1994990.6592616318   at iteration 4\n",
      "Delta: 10    ------     Final Loss: 1992207.8429168023   at iteration 19\n",
      "Delta: 100    ------     Final Loss: 1964496.978598407   at iteration 84\n",
      "Delta: 1000    ------     Final Loss: 1699162.6623283497   at iteration 201\n",
      "Delta: 10000    ------     Final Loss: 302150.77467486466   at iteration 64\n",
      "Delta: 100000    ------     Final Loss: 175474.63085276185   at iteration 70\n",
      "Delta: 1000000    ------     Final Loss: 146671.28662048402   at iteration 201\n",
      "Delta: 10000000    ------     Final Loss: 672843.1813172555   at iteration 201\n",
      "Delta: 100000000    ------     Final Loss: 1757112480.4694064   at iteration 201\n"
     ]
    }
   ],
   "source": [
    "deltas = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000]\n",
    "\n",
    "for delta in deltas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, delta = delta, max_iter=201, patience = 0.01, printing = False)\n",
    "  print('Delta: ' + str(delta) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--BkRQqIxmSw",
    "outputId": "f9c17983-9fb7-40c8-dc83-c9d8c099cf3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 250000    ------     Final Loss: 184966.58801373874   at iteration 142\n",
      "Delta: 500000    ------     Final Loss: 169552.51866399613   at iteration 201\n",
      "Delta: 750000    ------     Final Loss: 420615.6132565984   at iteration 201\n",
      "Delta: 1250000    ------     Final Loss: 216412.31880627264   at iteration 201\n",
      "Delta: 1500000    ------     Final Loss: 273680.42343568715   at iteration 201\n",
      "Delta: 2500000    ------     Final Loss: 417712.4612960932   at iteration 201\n",
      "Delta: 5000000    ------     Final Loss: 571545.4612269908   at iteration 201\n",
      "Delta: 7500000    ------     Final Loss: 632556.1542439449   at iteration 201\n"
     ]
    }
   ],
   "source": [
    "deltas = [250000,\n",
    "          500000,\n",
    "          750000,\n",
    "          1250000,\n",
    "          1500000,\n",
    "          2500000,\n",
    "          5000000,\n",
    "          7500000]\n",
    "\n",
    "for delta in deltas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, delta = delta, max_iter=201, patience = 0.01, printing = False)\n",
    "  print('Delta: ' + str(delta) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5Xei-9Gy3hh",
    "outputId": "47a9fd59-b0a5-4bca-ab08-992677a90c73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 150000    ------     Final Loss: 180502.69121015765   at iteration 95\n",
      "Delta: 300000    ------     Final Loss: 186151.14181067253   at iteration 165\n",
      "Delta: 450000    ------     Final Loss: 188191.3045520871   at iteration 231\n",
      "Delta: 600000    ------     Final Loss: 189243.6150128576   at iteration 297\n",
      "Delta: 900000    ------     Final Loss: 190318.32554160611   at iteration 425\n",
      "Delta: 1200000    ------     Final Loss: 189679.94593613478   at iteration 501\n",
      "Delta: 1500000    ------     Final Loss: 149600.4326080835   at iteration 501\n"
     ]
    }
   ],
   "source": [
    "deltas = [150000,\n",
    "          300000,\n",
    "          450000,\n",
    "          600000,\n",
    "          900000,\n",
    "          1200000,\n",
    "          1500000]\n",
    "\n",
    "for delta in deltas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, delta = delta, max_iter=501, patience = 0.01, printing = False)\n",
    "  print('Delta: ' + str(delta) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2W5PqtaH0eZu",
    "outputId": "c519e67f-c98e-4186-a5a2-8d0d6a031872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 1750000    ------     Final Loss: 191384.43819455765   at iteration 786\n",
      "Delta: 2000000    ------     Final Loss: 191527.2106760225   at iteration 889\n",
      "Delta: 2250000    ------     Final Loss: 191638.53051798942   at iteration 991\n"
     ]
    }
   ],
   "source": [
    "deltas = [1750000,\n",
    "          2000000,\n",
    "          2250000]\n",
    "\n",
    "for delta in deltas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, delta = delta, max_iter = 1000, patience = 0.001, printing = False)\n",
    "  print('Delta: ' + str(delta) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MkpvJqQi2YxJ",
    "outputId": "c4eeadcf-f4a5-4873-94aa-33a40b766bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: 1375000    ------     Final Loss: 191074.29727334835   at iteration 630\n",
      "Delta: 1500000    ------     Final Loss: 191194.6863524153   at iteration 682\n",
      "Delta: 1625000    ------     Final Loss: 191296.77299220837   at iteration 734\n"
     ]
    }
   ],
   "source": [
    "deltas = [1375000,\n",
    "          1500000,\n",
    "          1625000]\n",
    "\n",
    "for delta in deltas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, delta = delta, max_iter = 1000, patience = 0.001, printing = False)\n",
    "  print('Delta: ' + str(delta) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PO5uv6UZ33wJ"
   },
   "source": [
    "## Gammas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45FR0xoX323p",
    "outputId": "51369768-d4dc-4455-f573-83822546ef54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma1: 0   Gamma2: 0.1    ------     Final Loss: 335449.4737096828   at iteration 500\n",
      "Gamma1: 0   Gamma2: 1    ------     Final Loss: 335449.4737096833   at iteration 500\n",
      "Gamma1: 0.1   Gamma2: 1    ------     Final Loss: 149460.45148459333   at iteration 500\n",
      "Gamma1: 1   Gamma2: 1    ------     Final Loss: 149460.451484515   at iteration 500\n",
      "Gamma1: 1   Gamma2: 10    ------     Final Loss: 335449.47370968235   at iteration 500\n",
      "Gamma1: 1   Gamma2: 100    ------     Final Loss: 149460.4514845148   at iteration 500\n",
      "Gamma1: 10   Gamma2: 100    ------     Final Loss: 149460.451484515   at iteration 500\n"
     ]
    }
   ],
   "source": [
    "gammas = [[0,    0.1],\n",
    "          [0,    1],\n",
    "          [0.1,  1],\n",
    "          [1,    1],\n",
    "          [1,   10],\n",
    "          [1,  100],\n",
    "          [10, 100]]\n",
    "\n",
    "for gamma1, gamma2 in gammas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, gamma1 = gamma1, gamma2 = gamma2, delta = 1500000, max_iter = 500, patience = 0.001, printing = False)\n",
    "  print('Gamma1: ' + str(gamma1) + '   Gamma2: ' + str(gamma2) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EOD4CGHO884Z",
    "outputId": "f4ddeb2d-b605-4c9c-fab8-d096648bc3e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma1: 1   Gamma2: 100    ------     Final Loss: 149460.45148459318   at iteration 500\n",
      "Gamma1: 100   Gamma2: 100    ------     Final Loss: 149460.45148451466   at iteration 500\n",
      "Gamma1: 0.1   Gamma2: 100    ------     Final Loss: 149460.4514845149   at iteration 500\n",
      "Gamma1: 1   Gamma2: 1000    ------     Final Loss: 335449.4737115356   at iteration 500\n"
     ]
    }
   ],
   "source": [
    "gammas = [[1,  100],\n",
    "          [100, 100],\n",
    "          [0.1,  100],\n",
    "          [1,    1000]]\n",
    "\n",
    "for gamma1, gamma2 in gammas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, gamma1 = gamma1, gamma2 = gamma2, delta = 1500000, max_iter = 500, patience = 0.001, printing = False)\n",
    "  print('Gamma1: ' + str(gamma1) + '   Gamma2: ' + str(gamma2) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMpXvq5S-ZvP",
    "outputId": "ac623233-b516-433e-a7f7-041981b1ed94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma1: 0   Gamma2: 100    ------     Final Loss: 335449.47371153446   at iteration 500\n",
      "Gamma1: 0   Gamma2: 1000    ------     Final Loss: 149460.4514845933   at iteration 500\n",
      "Gamma1: 0.1   Gamma2: 0.1    ------     Final Loss: 149460.45148451495   at iteration 500\n"
     ]
    }
   ],
   "source": [
    "gammas = [[0,  100],\n",
    "          [0, 1000],\n",
    "          [0.1,  0.1]]\n",
    "\n",
    "for gamma1, gamma2 in gammas:\n",
    "  pred_ratings, loss, it = FW_inface(new_data, FW_objective_function, gamma1 = gamma1, gamma2 = gamma2, delta = 1500000, max_iter = 500, patience = 0.001, printing = False)\n",
    "  print('Gamma1: ' + str(gamma1) + '   Gamma2: ' + str(gamma2) + '    ------     Final Loss: ' + str(loss) + '   at iteration ' + str(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpS5jRz4vpHa"
   },
   "source": [
    "## Sub-Chapter"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FW_GoodReads_recommender - Copia.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
